---
title:  "[ChunK] 소리 합성 및 처리 - UGen의 활용"

categories:
  - ChunK
tags:
  - [ChunK, Music, UGen]

toc: true
toc_sticky: true

---

> 이 포스트는 한양대학교 음악프로그래밍(CSE2020) 도경구 교수님 수업을 참조하였습니다. 개인적으로 공부하면서 참조하려고 만든 포스트입니다.

# 소리 합성 및 처리 - UGen 의 활용

## 6-1 특수 내장 `UGen`
| 내장 (UGen) | Description                                                  |
| ----------- | ------------------------------------------------------------ |
| dac         | digital-analog converter, 스피커 또는 오디오 아웃풋 장치에 연결되어 외부로 소리를 내보냄 |
| adc         | analog-digital converter, 마이크 또는 오디오 인풋 장치에 연결되어 외부에서 소리를 받아들임. |
| blackhole   | 소리 정보를 받긴 하지만 스피커로 보내지 않는다.              |


인풋, 아웃풋 연결
다음 같이 인풋과 아웃풋을 연결할 수 있다

```java
adc => Gain g => dac;
10::second => now;
```
> 이 경우 실행하면 컴퓨터 마이크와 스피커가 연결되어, 마이크로 들어가는 소리가 Gain을 통과하여 컴퓨터 스피커로 들린다. 이미 써본 적이 있는 Gain은 연결되어 있는 UGen의 볼륨을 통합하여 조정할 수 있다. 위 프로그램을 실행하면 마이크와 스피커 간의 거리가 짧아서 스피커에서 나오는 소리가 다시 마이크로 들어가면서 피드백이라는 현상이 발생하여 귀를 찢을 듯한 견디기 힘든 소리가 날 수 있다. 따라서 실행하기 전 스피커 볼륨을 최대한 낮추기를 권한다. 이 연결은 10초 동안 지속된다. 중간 다리 역할을 하는 Gain은 소리 크기를 조절하는 것 이외에 특별히 할 일은 없지만 두지 않을 수 없는 이유가 있다.

>만약 다음과 같이 인풋과 아웃풋을 직접 연결하면 10초가 지나고 프로그램의 실행이 끝난 이후에도 연결된 상태가 지속된다. 왜냐하면, adc와 dac는 프로그램의 실행과 상관없이 항상 존재하기 때문이다.
> adc 와 dac는 항상 프로그램시작하면 계속 작동하고 있다. 프로그램이 끝나고 계속 adc 와 dac 는 끊어지지 않고 연결되어있다.
> 그러므로 직접 연결하는 것은 좋지 않다.


인풋만 사용
인풋을 받아야 하지만 스피커로 내보내고 싶지 않다면, 다음과 같이 dac 대신 blackhole에 연결하면 된다.

```java
adc => Gain g => blackhole;
while (true) {
    if (g.last() > 0.9) 
        <<< "Loud!!", g.last() >>>;
    samp => now;
}
```

> 위 코드처럼 사용하면, 마이크로 들어오는 소리가 재생되는것이아닌, 마이크로 들어온 소리를가지고
> 내가 뭔가를 하고 싶을때 blackhole 에 연결시키면된다. Gain이 0.9 이상일때 print 값이 찍히게 된다.
> g.last()는 Gain UGen g를 통과한 가장 최근 샘플을 알려준다.

## 6-2 PulseOsc

PulseOsc는 파형의 모양이 아래 그림과 같이 SqrOsc와 동일하다. 하지만 파형의 너비를 조절할 수 있다는 점이 SqrOsc와 다르다.
![image](https://user-images.githubusercontent.com/69495129/137003378-995745d4-c648-4ffd-884d-7e45cccba73b.png)

올라가는 파형과 내려가는 파형의 넓이가 같으면 SqrOsc 이다. 
PulseOsc 는 파형의 넓이를 수정할 수 있다.
기본값은 0.5로 setting 이 되어있다.

>너비는 .width 변수가 기억하고, 기본값은 0.5로 설정되어 있다. 따라서 설정을 바꾸지 않으면 SqrOsc와 같다. 0.5의 의미는 파형에서 올라간 부분과 내려간 부분의 너비가 반반씩으로 같다는 의미이다. 따라서 0.1로 설정하면, 파형 한 주기의 길이는 변화없이 한쪽의 너비가 10%, 반대쪽의 너비가 90%가 된다. 0.9로 설정하면, 올라간 부분이 90%, 내려간 부분이 10%가 되어 파형의 모양은 달라 보이지만 소리는 동일하다. 소리의 다름은 너비의 비율 차이에 따라서만 다르게 들리기 때문이다. 따라서 사실상 값에 따라 다른 소리가 나는 .width 변수의 범위는 0.0~0.5 이다. 다음 프로그램에서 .width 값에 변화를 주면서 소리가 어떻게 달라지는지 들어보자.
> 파형의 넓이가 달라지게 되면 소리가 달라진다.

```java
PulseOsc p => dac;
0.0 => p.width;
while (true) {
    if (Math.random2(0,1))
        84.0 => p.freq; // E2
    else
        100.0 => p.freq; // G2
    1 => p.gain;
    0.09::second => now;
    0 => p.gain;
    0.06::second => now;
}
```

위 코드는 PulseOsc 의 width 를 0.0 으로 둔것이다.
랜덤으로 파형의 넓이를 지정해보자.
너비를 0.01 부터 0.5 까지 랜덤하게 선택했다 0.5부터 0.99 까지는 앞의 랜덤하게 선택된값과
같은 소리를 낼것이므로 0.5까지만 선택한다.
```java
PulseOsc p => dac;
while (true) {
    Math.random2f(0.01,0.5) => p.width;
    if (Math.random2(0,1))
        84.0 => p.freq; // E2
    else
        100.0 => p.freq; // G2
    1 => p.gain;
    0.09::second => now;
    0 => p.gain;
    0.06::second => now;
}
```

## 6-3 `Envelope`
`봉투에 넣으면 정돈된 느낌이 든다 => 소리를 다듬는다.`
> 지금까지 소리는 처음부터 끝까지가 균일한 볼륨으로 들린다. 연이어 들리는 소리가 끊겨 들리게 하기 위해서 소리의 뒷 부분을 죽이기도 했다. 그런데 자연에서 나는 소리는 시작 부분에서 점진적으로 커지고, 끝 부분에서 점진적으로 작아진다. 노래할 때나, 악기를 불거나, 켜거나, 칠때도 마찬가지다. 우리가 프로그램으로 만드는 소리를 바깥 세상에서 나는 소리와 마찬가지로 자연스럽게 낼 수 있도록 해주는 UGen이 Envelope 이다.
> 자연의 소리는 0에서 내가 원하는 볼륨으로 바로 툭! 하고 가는경우는없고 자연의소리는 소리가 나는 시점부터 서서히 올라갔다가 서서히 내려가서 소리내는게끝나면 소리가 사라진다.
> 피아노 건반을 누를때도 마찬가지이다. 건반을 때리는순간 0부터 특정 지점까지 올라갔다가 천천히 내려와서 소리가 사라진다.
> 지금까지는 임의로 소리를끊어줬기때문에 어색한 부분이 있었다.

SqrOsc 는 `목관악기` 랑 소리가 비슷하다고 한다. 
envelope 을 통과시켜준다.
envelope 을 통과시키면서 신호를 보내면 신호를 보낸 그 시점부터 소리가 서서히 올라간다
그것이 `keyOn` 이라는 명령어이다. 그때부터 소리가 서서히 올라간다.
`keyOff` 라는 신호를 보내면 그때부터 소리가 점진적으로 0.0 으로 줄어든다.
이 두 신호는 envelope 한테 보내는 신호이다.
```java
SqrOsc clarinet => Envelope env => dac;
[48,50,52,53,55,57,59,60] @=> int scale[];
for (0 => int i; i < scale.size(); i++) {
    Std.mtof(scale[i]) => clarinet.freq;
    1 => env.keyOn;  
    0.25::second => now;
    1 => env.keyOff;
    0.25 :: second => now;
}
```

> keyOn 과 keyOff 를 사용하는 timing 을 조절하므로써 더 부드러운 소리를 낼 수 있다.
> 지금까지는 임의로 소리를 안나게 했다.

| Envelope | 의미                                                 | 값   | 타입 |
| -------- | ---------------------------------------------------- | ---- | ---- |
| .keyOn   | 소리의 크기를 점진적으로 target() 까지 올리라는 신호 | 1    | int  |
| .keyOff  | 소리의 크기를 점진적으로 0.0 까지 내리라는 신호      | 1    | int  |



| envelope 미사용                                              | envelope 사용                                                |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![image](https://user-images.githubusercontent.com/69495129/137004718-e26f5130-0494-4811-8920-b98754a08cea.png) | ![image](https://user-images.githubusercontent.com/69495129/137004746-5f05e7d1-eed2-4860-9cf7-035f879d2de1.png) |


>그리고 다음 Envelope 변수 값을 변경하여 소리의 처음과 끝 부분의 경사 및 소리 크기를 원하는대로 조정할 수 있다.


| Envelope  | 의미                 | 기본 설정값  | 타입  |
| --------- | -------------------- | ------------ | ----- |
| .target   | 최대 소리 크기       | 1.0          | float |
| .time     | 목표에 도달하는 시간 | 0.022676(초) | float |
| .duration | 목표에 도달하는 시간 | 1000(샘플)   | dur   |
| .value    | 소리 크기 일시 설정  | 0.0          | float |

`.value` 는 어떤 한 소리에 대해서만 소리를 크게하거나 작게하거나 setting 할 수 있다.

## 6-3-2 `SawOsc`와 `ADSR` 을 활용하여 바이올린 소리 만들기

>바이올린은 목관악기랑은 다르다. 바이올린은 활로 줄을 밀때 처음에는 저항값이 엄청크다 그래서 딱 걸리고
> 처음에는 소리를 시작하지못하다가 특정 저항값을 이기면 그때부터 소리가 나게된다.

![image](https://user-images.githubusercontent.com/69495129/137005577-69d21977-d24e-4329-8679-c402d1880e8d.png)

> 위 그림에 대한 설명 : 저항하다가 소리가 커졌다가 살짝 줄고 유지를하다가 소리가 점점준다.
> 이것이 바이올린을 켤때의 소리와 유사하다고 한다.

>ADSR도 특별한 형태의 Envelope 이므로 keyOn 과 keyOff 가 있다.

- `Attack`은 설정된 소리 크기(기본 1.0)까지 점진적으로 올라가는 구간이고,
- `Decay`는 정점에서 일정 소리 크기까지 내려가는 구간이고,
- `Sustain`은 일정 소리 크기로 유지하는 구간이고,
- `Release`는 소리를 점진적으로 끄는 구간이다.

```java
SawOsc violin => ADSR env => dac;
0.1::second => env.attackTime; // Attack 구간
0.1::second => env.decayTime; // Decay 구간
0.5 => env.sustainLevel; // Sustain 소리 크기
0.1::second => env.releaseTime; // Release 구간
```
또는 다음과 같이 .set 메소드 호출 한번으로 모두 한꺼번에 간편하게 설정할 수도 있다.

```java
SawOsc violin => ADSR env => dac;
env.set(0.1::second, 0.1::second, 0.5, 0.1::second)
```
순서대로 attack decay sustain release 이다

다음 프로그램을 실행하여 소리를 들어보자.

```java
SawOsc violin => ADSR env => dac;
env.set(0.1::second, 0.1::second, 0.5, 0.1::second);

[62,64,66,67,69,71,73,74] @=> int scale[];  // D major Scale
for (0 => int i; i < scale.size(); i++) {
    Std.mtof(scale[i]) => violin.freq;
    1 => env.keyOn;
    0.4::second => now;
    1 => env.keyOff; 
    0.2::second => now;
}
```

>위 코드를 살펴보자 sustain 은 소리의 크기만 지정하고 소리의 길이를 지정하지 않는다
> 왜냐하면 for 문안에 second 에서 총 시간을 정하고 거기서 나머지 시간을 빼면 sustain 의 시간이 자동으로 계산되기때문에
> sustain 은 특별히 시간(dur) 을 정하지 않는다.

>Attack, Decay 하는데 합하여 0.2초로 설정되어 있는데, .keyOn을 시작하고 0.4초를 보내므로 Sustain 하는 기간은 0.2초이다. Sustain하는 기간 중의 소리 크기는 설정한 대로 0.5 이다. .keyOff를 시작하고 보내는 시간인 0.1초는 설정된 Release 기간과 일치한다.

바이올린 소리와 비슷해졌지만 바이올린 특유의 떨림음인 비브라토(vibrato) 효과가 나도록 소리를 변조할 수도 있다. 아래 그림과 같이 비브라토 효과를 전담할 SinOsc을 연결하고,

>비브라토 : 음악 연주에서 목소리나 악기의 소리를 떨리게 하는 기교
![image](https://user-images.githubusercontent.com/69495129/137007737-576d5159-262d-4cfb-a09b-cb0a32f725d7.png)

> SinOsc 를 SawOsc 에 연결한다 SawOsc 는 어떤 다른 소리가 나한테 들어와서 그 소리와
> 나의 소리와 sync 를 맞춘다 라는 의미에서 sync 를 설정한다.
> 즉 sawOsc 는 나는 다른소리를 받아서 그거하고 sync를 맞춰서 소리를 변조한다.


>연결한 SinOsc vibrato를 SawOsc violin의 주파수 변조용으로 사용하도록 다음과 같이 .sync 변수를 2로 설정한다. 그리고 SinOsc vibrato의 주파수를 매우 낮게 6.0 설정한다. 이 프로그램을 실행해보면 약간의 비브라토가 추가되었음을 들을 수 있다.

```java
SinOsc vibrato => SawOsc violin => ADSR env => dac;
2 => violin.sync;   
6.0 => vibrato.freq;
env.set(0.1::second, 0.1::second, 0.5, 0.1::second);

[62,64,66,67,69,71,73,74] @=> int scale[];  // D major Scale
for (0 => int i; i < scale.size(); i++) {
    Std.mtof(scale[i]) => violin.freq;
    1 => env.keyOn;
    0.3::second => now;
    1 => env.keyOff; 
    0.1::second => now;
}
1 => env.keyOn;
10.0 => vibrato.gain;
1.0::second => now;
1 => env.keyOff;
0.2::second => now;
```
> 위 코드를 들어보면 약간 울리는 소리를 들을 수 있다.
> 마지막부분에서 gain 을 엄청 높히면 더 잘 들을 수 있다
> freq 가 너무나 낮기때문에 gain 을 엄청 높혀도 그렇게 큰 소리는 나지 않는다.




> 비브라도 효과를 할 SinOsc 그리고 소리의 중심인 SawOsc 
> vibrato 에는 아주작은 frequency 부여 



![image](https://user-images.githubusercontent.com/69495129/137008337-e4757cf9-249f-4dde-a7ea-cb55c2d63308.png)



# 6-4 주파수 변주로 소리 합성

>비브라토 효과를 내는 것과 같은 방식으로 두 개의 SinOsc를 연결하여 다양한 소리를 합성할 수 있다. 이를 주파수 변조(Frequency Modulation, 줄여서 FM)를 이용한 소리 합성 이라고 한다. 연결한 두 개의 진동기 중에서 주는 진동기를 변조기(modulator)라고 하고, 받는 진동기를 운반기(carrier)라고 한다.

> 두개의 모양이 섞이면 다른 모양의 파형이 생긴다.

![image](https://user-images.githubusercontent.com/69495129/137008064-0affac67-8876-4ce4-b484-55a0f476fc65.png)

> 위에서의 SinOsc(변조해주는역할) 이 modulator 이고 소리를 받는 중심 SawOsc 가 carrier 역할이다.
> modulator 는 signal 이 느슨하고 carrier 는 촘촘하다  modulator 가 음수가 되면 carrier 에서 빼게 되므로 느슨해진다.

```java
SinOsc modulator => SinOsc carrier => ADSR env => dac;
2 => carrier.sync;   
1000 => modulator.gain;
env.set(0.1::second, 0.1::second, 0.5, 0.1::second);

[62,64,66,67,69,71,73,74] @=> int scale[];  // D major Scale
for (0 => int i; i < scale.size(); i++) {
    Std.mtof(scale[i]) => carrier.freq => modulator.freq;
    1 => env.keyOn;
    0.4::second => now;
    1 => env.keyOff; 
    0.1::second => now;
}
```

> 위 코드는 소리합성의 코드이다. FM 은 주로 SinOsc 음파를 2개 합성해서 새로운 모양을 만들어낸다.
> carrier 는 sync 를 2로 설정해주는것을 잊지 말자.

>운반기(carrier) 의  .sync를 주파수 변조 모드인 2로 설정하고, 변조기 modulator의 .gain을 매우 높은 값인 1000으로 설정하였다. modulator.gain 값을 다양하게 바꾸어서 소리의 변화를 들어보자.
>이어서 다음 프로그램을 실행하여 변조기와 운반기의 주파수에 따라서 소리가 어떻게 바뀌는지 들어보자.

```java
SinOsc modulator => SinOsc carrier => ADSR env => dac;
2 => carrier.sync;   
1000 => modulator.gain;
env.set(0.1::second, 0.1::second, 0.5, 0.1::second);

while (true) {
    Math.random2f(300.0,1000.0) => carrier.freq;
    Math.random2f(300.0,1000.0) => modulator.freq;
    1 => env.keyOn;
    0.4::second => now;
    1 => env.keyOff; 
    0.1::second => now;
}
```
>주파수는 가청주파수 300에서 1000사이로 지정했다.

>주파수의 비율이 정수(1:2, 2:1, 2:3, 1:3, …)인 경우에만 화음이 맞고, 그렇지 않으면 불협화음 소리가 난다.
> 그래서 어떤소리는 듣기좋은 소리가 나고 , 어떤 소리는 듣기 안좋은 소리가 난 것이다.
>사인파형(SinOsc)만 가지고 주파수 변조를 활용하면 다양한 소리를 합성할 수 있다. ChucK에서는 주파수 변조로 만든 STK(Synthesis Tool Kit)라고 하는 다양한 악기 소리를 가진 내장 UGen를 갖추고 있다. 예를 들어 전기 피아노 소리는 Rhodey와 Wurley 두 가지가 있는데 테스트 삼아 다음 프로그램을 실행하여 소리를 들어보자.

>이미 소리를 많이 만들어놓았다. 그것을 우리는 이용하면 된다.
> 밑의 피아노는 소리가 이미 만들어져 있기때문에 연주만 하면 된다.
> UGen 자체에 env 도 장착이 되어있다.

![image](https://user-images.githubusercontent.com/69495129/137009805-1b52cdd4-e5eb-422b-be3b-8a1d9ddfbe6a.png)

```java
Wurley epiano => dac;
while (true) {
    Math.random2f(100.0,300.0) => epiano.freq;    
    1 => epiano.noteOn;
    Math.random2f(0.2,0.5)::second => now;
    1 => epiano.noteOff;
    Math.random2f(0.05,0.1)::second => now;
}
```

`ChucK가 제공하는 FM으로 만든 내장 STK 악기를 나열하면 다음과 같다`

- 전기 피아노 : Rhodey, Wurley
- 오르간 : BeeThree
- 목관악기 : PercFlut
- 전기 기타 : HevyMetl
- 타악기 : TubeBell
- 사람 목소리 : FMVoices, VoicForm

`사실 사람목소리는 많이 안 비슷한것 같다.`

> 위 FM 합성과정으로는 실제 악기의 소리를 정확히 구현하는데에는 한계가 있다. 그러므로 물리적 모델링으로 소리를 합성하여 실제 자연의 소리를 내보자

## 6-5 물리적 모델링으로 소리 합성

>소리를 내는 실물의 물리적 구조 정보로 수학적 모델을 만들어 소리를 합성하는 방식을 물리적 모델링(Physical Modelling, PM)이라고 한다. 이 절에서는 Karplus와 Strong이 고안한 알고리즘으로 줄 튕기는 소리를 합성해본다.

> 수학식을 가지고 파형을 강제로 만들어서 자연에서 나는 소리와 비슷하게 만든다.

### 6-5-1  줄 튕기는 소리 합성 - Impulse에 Delay 적용 (탐구)
```java
Impulse imp => dac;
while (true) {
    1.0 => imp.next;
    0.1::second => now;
}
```
> 줄 튕기는 소리를 관찰한 다음에 그거와 비슷하게 파형을 만든 알고리즘이다.
> Impulse UGen 을 소리나게 하는 방법은 imp.next를 1로 설정해주면 된다.

이번에는 펄스 소리가 나는 간격을 다르게 설정하여 소리를 들어보자.

```java
Impulse imp => dac;
while (true) {
    1.0 => imp.next;
    Math.random2f(0.01,0.1)::second => now;
}
```

Impulse 를 Delay 라는 UGen 을 통과시킨다.
Delay는 소리를 받으면 소리를 바로 내보내는것이아니라 ,조금 있다가 내보낸다.

```java
Impulse imp => Delay str => dac;
str => str;
1.0 => imp.next;
2::second => now;
```

위 코드를 이해하는데에는 살짝어려움이있다. 일단 실행을 시키면 imp.next 에의해서 소리가 한번나고
2초가지난후(프로그램이 끝난후) str 이 feedback loop 을 돌면서 저장해뒀던 feedback 을 마지막에 뱉고 프로그램이 종료된다.


>d.delay의 기본 설정 값이 0.0으로 설정되어 있기 때문에 전혀 지연이 없다. 바로 펄스 소리가 난다. str => str은 피드백 루프(feedback loop)라고 하는데 나가는 소리가 자신에게 다시 들어가는 구조이다. 이 경우 지연이 전혀 없기 때문에 다시 들어가더라도 모두 동시에 나가므로 펄스 소리가 한 번만 난다. 단, 시간이 다 지나가면 피드백한 소리가 있으므로 이를 한 번 내주고 끝난다.

```java
Impulse imp => Delay str => dac;
str => str;
441.0::samp => str.delay;
1.0 => imp.next;
2::second => now;
```

0.01초 지연되여 소리가 나가는데, 피드백 루프 때문에 0.01초에 한번씩 지속적으로 소리가 난다. 총 2초 동안 200번 펄스 소리가 연속하여 난 것이다.

그런데 다음 프로그램과 같이 .gain을 1.0 보다 작게 설정하면, 피드백 루프로 되돌아 들어가면서 그 만큼 소리 크기가 줄어든다. 이 프로그램을 실행하여 소리에 어떤 변화가 있는지 들어보자.

```java
Impulse imp => Delay str => dac;
str => str;
441.0::samp => str.delay;
0.98 => str.gain;
1.0 => imp.next;
2::second => now;
```
줄을 튕기면 바로 소리가 나지만 시간이 지나면서 서서히 소리가 사라진다. 아직 소리가 좀 어설프긴 하지만 소리가 점차 사라지는 효과는 얻었다.

### 6-5-2 줄 튕기는 소리 합성 - Noise에 Delay 적용하여 개선

>그런데 사실 이 소리를 최초로 합성한 연구자는 Noise에 Delay를 적용하였으므로 그렇게 해보자. Impulse는 소리가 한 번 짧게 나고 말기 때문에 피드백 루프 효과를 쉽게 얻을 수 있지만, Noise는 연속해서 소리가 나기 때문에 짧게 자르는 작업을 해야 한다. 길이는 지연 시간만큼으로 하고 바로 소리를 끈다. 다음 프로그램을 이해하고 실행하여 소리를 들어보자.

```java
Noise nois => Delay str => dac;
str => str;
441.0::samp => str.delay;
0.98 => str.gain;

1.0 => nois.gain;
441.0::samp => now;
0.0 => nois.gain;

3.0 :: second => now;
```

### 6-5-3. 줄 튕기는 소리 합성 - 필터를 통과시켜 소리 개선

>소리는 사라지면서 높은 주파수가 낮은 주파수에 비해 빨리 사라지는 현상을 적용한 OneZero 필터를 다음과 같이 피드백 루프에 끼우면 소리를 더 실제와 가깝게 개선할 수 있다. 다음 프로그램을 실행하여 소리를 들어보자.


```java
Noise nois => Delay str => dac;
str => OneZero filter => str;
441.0::samp => str.delay;
0.98 => str.gain;

1.0 => nois.gain;
441.0::samp => now;
0.0 => nois.gain;

3.0 :: second => now;
```

>지금까지 사용한 Delay는 주파수의 크고 작음에 따라서 오차가 발생할 가능성이 있다. 이를 보정(튜닝)하기 위해서 보간법을 적용한 DelayA와 DelayL이 있다. 이를 활용하면 소리가 얼마나 개선되는지 각각 들어보자.
>여기에서도 ADSR을 적용할 수 있다. 마찬가지로 실행하여 소리를 들어보자.

```java
Noise nois => ADSR pluck => Delay str => dac;
str => OneZero filter => str;
441.0::samp => str.delay;
0.98 => str.gain;
pluck.set(0.002::second, 0.002::second, 0.0, 0.01::second);

1 => pluck.keyOn;
3.0 :: second => now;
```

```java
Noise nois => ADSR pluck => DelayA str => dac;
str => OneZero lowPass => str;
pluck.set(0.002::second, 0.002::second, 0.0, 0.01::second);

while (true) {
    Math.random2f(110.0, 440.0)::samp => str.delay;
    1 => pluck.keyOn;
    0.3 :: second => now;
}
```

## 6-6 필터

### 6-6-1. ResonZ
ResonZ 필터는 소리에 공명(resonance, echo)을 더해주는 역할을 한다.
ResonZ 필터를 끼운 다음 프로그램의 소리를 들어보자.
```java
Impulse imp => ResonZ filter => dac;
100.0 => filter.Q; // Quality, amount of resonance

while (true) {
    Math.random2f(500.0,2500.0) => filter.freq;
    100.0 => imp.next; 
    0.1 :: second => now;
}
```

## 6-7소리에 특수효과 추가하기

>소리는 생기면 사방으로 퍼져나간다. 그러다 벽이나 천장, 바닥 같은 물체에 부딛치면 반사를 하여 다시 퍼져 나간다. 예를 들어 방에서 어떤 소리를 듣는다면 그 소리는 직접 귀에 도달한 소리와 반사된 소리를 동시에 듣게 된다. 그런데 직접 도달한 소리와 물체에 반사되어 도달한 소리는 미소하지만 시차가 있으므로 울림(메아리, reverberation, echo)로 들린다. Delay를 사용하면 이러한 울림 소리를 합성할 수 있다.

다음 프로그램은 이 방에서 나는 소리가 우리 귀에 어떻게 들릴지 합성한 프로그램이다. 울림 효과는 소리 속도와 듣는자의 위치, 방의 규모를 감안하여 계산하였다.

```java

// connect mic to speaker
adc => Gain input => dac;
1.0 => input.gain;
// walls and ceiling
input => Delay d1 => dac;
input => Delay d2 => dac;
input => Delay d3 => dac;
// delay loop
d1 => d1;
d2 => d2;
d3 => d3;
// set feedback/loss on all delay lines
0.6 => d1.gain => d2.gain => d3.gain;
// allocate memory and set delay lengths
0.06::second => d1.max => d1.delay;
0.08::second => d2.max => d2.delay;
0.10::second => d3.max => d3.delay;
// sit back and enjoy the room
while (true)
    1.0 :: second => now;
```

## 6-9 사례학습

```java
// Musical fun with a resonant filter and three delay lines
Impulse imp => ResonZ rez => Gain input => dac;
100 => rez.Q;
100 => rez.gain;
1.0 => input.gain;

Delay del[3];
input => del[0] => dac.left;
input => del[1] => dac;
input => del[2] => dac.right;

for (0 => int i; i < 3; i++) {
    del[i] => del[i];
    0.6 => del[i].gain;
    (0.8 + i*0.3)::second => del[i].max => del[i].delay;
}

[60, 64, 65, 67, 70, 72] @=> int notes[];
notes.cap() - 1 => int numNotes;
while (true) {
    Std.mtof(notes[Math.random2(0,numNotes)]) => rez.freq;
    1.0 => imp.next;
    0.4::second => now;
}
```
## Summary
- UGen 은 뭔가 추상적이여서 어려운것 같다. 익숙해지는게 먼저인것 같다.
***


🌜 주관적인 견해가 담긴 글입니다. 다양한 의견이 있으실 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄

